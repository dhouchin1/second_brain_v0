# Database
DB_PATH=./notes.db
DATABASE_URL=sqlite:///./notes.db
# For service-layer modules that read these envs directly
SQLITE_DB=notes.db
SQLITE_VEC_PATH=/absolute/path/to/sqlite-vec0.dylib   # optional; .so on Linux

# Paths
# Obsidian vault (root impl uses VAULT_PATH; services impl uses OBSIDIAN_* envs)
VAULT_PATH=./vault
OBSIDIAN_VAULT_PATH=./vault
OBSIDIAN_PROJECTS_ROOT=Projects
OBSIDIAN_PER_PROJECT=true
AUDIO_DIR=./audio
UPLOADS_DIR=./uploads
WHISPER_CPP_PATH=./whisper.cpp/build/bin/whisper-cli
WHISPER_MODEL_PATH=./whisper.cpp/models/ggml-base.en.bin

# AI Services (LLM)
OLLAMA_API_URL=http://localhost:11434/api/generate
# Recommended lightweight model for local use
OLLAMA_MODEL=phi3:mini
# Optional performance/resource knobs
OLLAMA_NUM_CTX=1024
OLLAMA_NUM_PREDICT=256
OLLAMA_TEMPERATURE=0.2
OLLAMA_TOP_P=0.8
# Set if you want to force CPU (0) or choose GPUs explicitly
# OLLAMA_NUM_GPU=0

# Security
SECRET_KEY=your-super-secret-key-here
WEBHOOK_TOKEN=your-webhook-token

# Discord
DISCORD_BOT_TOKEN=your-discord-bot-token

# Optional Cloud Services
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key

# Transcriber Settings
# Choose 'vosk' for lightweight CPU-only ASR, or 'whisper' for whisper.cpp
TRANSCRIBER=vosk
# Path to the unpacked Vosk model directory (example below)
# Download from: https://alphacephei.com/vosk/models
# e.g. https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip
VOSK_MODEL_PATH=/Users/youruser/models/vosk/vosk-model-small-en-us-0.15

# Processing limits
# Increase if you plan larger uploads (bytes)
MAX_FILE_SIZE=209715200   # 200 MB
PROCESSING_CONCURRENCY=1
TRANSCRIPTION_CONCURRENCY=1
PROCESSING_TIMEOUT_SECONDS=1800  # 30 minutes

# AI processing controls (to reduce CPU/RAM usage)
AI_PROCESSING_ENABLED=true
AI_CHUNK_SIZE_CHARS=1500
AI_THROTTLE_DELAY_SECONDS=2
